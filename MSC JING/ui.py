# -*- coding: utf-8 -*-import tkinter as tkimport serialimport threadingimport queueimport winsoundfrom datetime import datetime  # 导入datetime模块import re  # 导入re模块import cv2import torchimport torch.nn as nnimport numpy as npfrom statistics import modeimport warningsimport oswarnings.filterwarnings("ignore")# 创建串口对象ser = serial.Serial('COM9', 115200)  # 根据实际情况修改串口号和波特率# 创建队列来存储串口数据data_queue = queue.Queue()# 记录程序开始运行的时间program_start_time = datetime.now()# 后台线程：串口通信def serial_thread():    try:        while True:            data = ser.readline().decode('utf-8')  # 读取一行数据并解码            data_queue.put(data)  # 将数据放入队列    except KeyboardInterrupt:        pass  # 当按下 Ctrl+C 时停止循环    ser.close()# 后台线程：更新UI和播放提示音def update_ui():    global one_click    one_click=False    global flag    flag=0    global Test_number    Test_number=1    global save_counter    save_counter = 1  # 初始化保存计数器    while True:        try:            data = data_queue.get_nowait()  # 从队列获取数据            # 获取当前时间            current_time = datetime.now()            # 计算从程序开始到串口有输入的时间间隔            time_since_start = current_time - program_start_time            time_since_start_str = str(time_since_start)            # text_widget.insert(tk.END, data)  # 在文本框中插入数据            if flag==0:                text_widget.insert(tk.END, f'Test No.{Test_number}\n')                Test_number+=1            # if '#' in data:            #    text_widget.insert(tk.END, 'chosen emotion Dominance：light\n')            #    # one_click = True            #    flag=flag+1            # if '*' in data:            #    text_widget.insert(tk.END, 'chosen emotion Dominance：Strong\n')            #    # one_click = True            #    flag = flag + 1                # if '4' in data :                #     text_widget.insert(tk.END, 'chosen emotion：angry\n')                #     one_click = 1                # if '5' in data :                #     text_widget.insert(tk.END, 'chosen emotion：angry\n')                #     one_click = 1                # if '6' in data :                #     text_widget.insert(tk.END, 'chosen emotion：angry\n')                #     one_click = 1                # if '7' in data :                #     text_widget.insert(tk.END, 'chosen emotion：angry\n')                #     one_click = 1                # if '8' in data :                #     text_widget.insert(tk.END, 'chosen emotion：angry\n')                #     one_click = 1                # if '9' in data :                #     text_widget.insert(tk.END, 'chosen emotion：angry\n')                #     one_click = 1                # if '0' in data :                #     text_widget.insert(tk.END, 'chosen emotion：angry\n')                #     one_click = 1            text_widget.see(tk.END)  # 自动滚动到最后一行            # 播放提示音            winsound.Beep(1000, 300)  # 频率和时长（毫秒）            # file_name = f"ui_content_{save_counter}.txt"  # 生成带有计数器的文件名            # content_to_save = text_widget.get("1.0", tk.END)  # 获取当前文本框的全部内容            # save_to_file(content_to_save, file_name)  # 保存内容到文件            # save_counter += 1  # 增加保存计数器            # 获取当前时间字符串            current_time_str = current_time.strftime('%Y-%m-%d %H:%M:%S')            text_widget.insert(tk.END, '时间：' + current_time_str + '\n')  # 在文本框中插入时间            # 输出从程序开始到串口有输入的时间间隔            text_widget.insert(tk.END, 'the time from the beginning：' + time_since_start_str + '\n')            # 使用正则表达式提取"val:"后面的数字            match = re.search(r'val:(\d+)', data)            if match :                extracted_val = match.group(1)  # 获取提取到的数字                # text_widget.insert(tk.END, '提取到的数字：' + extracted_val + '\n')  # 在文本框中插入提取到的数字                # 判断提取到的数字并输出相应的情绪                if extracted_val == '4':                    text_widget.insert(tk.END, 'chosen emotion Valence：light\n')  # 在文本框中插入情绪                    # one_click = True                    flag = flag + 1                elif extracted_val == '5':                    text_widget.insert(tk.END, 'chosen emotion Valence：medium\n')  # 在文本框中插入情绪                    # one_click = True                    flag = flag + 1                elif extracted_val == '6':                    text_widget.insert(tk.END, 'chosen emotion Valence：strong\n')                    # one_click = True                    flag = flag + 1                elif extracted_val == '7':                    text_widget.insert(tk.END, 'chosen emotion Arousal：light\n')                    # one_click = True                    flag = flag + 1                elif extracted_val == '8':                    text_widget.insert(tk.END, 'chosen emotion Arousal：medium\n')                    # one_click = True                    flag = flag + 1                elif extracted_val == '9':                    text_widget.insert(tk.END, 'chosen emotion Arousal：strong\n')                    # one_click = True                    flag = flag + 1                elif extracted_val == '0':                    text_widget.insert(tk.END, 'chosen emotion Dominance：medium\n')                    # one_click = True                    flag = flag + 1                text_widget.see(tk.END)  # 自动滚动到最后一行            if '#' in data:               text_widget.insert(tk.END, 'chosen emotion Dominance：Strong\n')               # one_click = True               flag=flag+1            if '*' in data:               text_widget.insert(tk.END, 'chosen emotion Dominance：light\n')               # one_click = True               flag = flag + 1        except queue.Empty:            passdef preprocess_input(images):    images = images / 255.0    return imagesdef gaussian_weights_init(m):    classname = m.__class__.__name__    # 字符串查找find，找不到返回-1，不等-1即字符串中含有该字符    if classname.find('Conv') != -1:        m.weight.data.normal_(0.0, 0.04)class FaceCNN(nn.Module):    # 初始化网络结构    def __init__(self):        super(FaceCNN, self).__init__()        # 第一次卷积、池化        self.conv1 = nn.Sequential(                nn.Conv2d(in_channels = 1, out_channels = 64, kernel_size = 3, stride = 1, padding = 1),  # 卷积层                nn.BatchNorm2d(num_features = 64),  # 归一化                nn.RReLU(inplace = True),  # 激活函数                nn.MaxPool2d(kernel_size = 2, stride = 2),  # 最大值池化                )        # 第二次卷积、池化        self.conv2 = nn.Sequential(                nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size = 3, stride = 1, padding = 1),                nn.BatchNorm2d(num_features = 128),                nn.RReLU(inplace = True),                nn.MaxPool2d(kernel_size = 2, stride = 2),                )        # 第三次卷积、池化        self.conv3 = nn.Sequential(                nn.Conv2d(in_channels = 128, out_channels = 256, kernel_size = 3, stride = 1, padding = 1),                nn.BatchNorm2d(num_features = 256),                nn.RReLU(inplace = True),                nn.MaxPool2d(kernel_size = 2, stride = 2),                )        # 参数初始化        self.conv1.apply(gaussian_weights_init)        self.conv2.apply(gaussian_weights_init)        self.conv3.apply(gaussian_weights_init)        # 全连接层        self.fc = nn.Sequential(                nn.Dropout(p = 0.2),                nn.Linear(in_features = 256 * 6 * 6, out_features = 4096),                nn.RReLU(inplace = True),                nn.Dropout(p = 0.5),                nn.Linear(in_features = 4096, out_features = 1024),                nn.RReLU(inplace = True),                nn.Linear(in_features = 1024, out_features = 256),                nn.RReLU(inplace = True),                nn.Linear(in_features = 256, out_features = 7),                )    # 前向传播    def forward(self, x):        x = self.conv1(x)        x = self.conv2(x)        x = self.conv3(x)        # 数据扁平化        x = x.view(x.shape[0], -1)        y = self.fc(x)        return ydef facial_detect():    # 面部识别分类器    global one_click    global flag    detection_model_path = 'model/haarcascade_frontalface_default.xml'    classification_model_path = 'model/model_cnn.pt'    # 加载人脸检测模型    face_detection = cv2.CascadeClassifier(detection_model_path)    # 加载表情识别模型    emotion_classifier = torch.load(classification_model_path)    frame_window = 10    # 表情标签    emotion_labels = {0: 'angry', 1: 'disgust', 2: 'fear', 3: 'happy', 4: 'sad', 5: 'surprise', 6: 'neutral'}    emotion_window = []    # 调起摄像头    video_capture = cv2.VideoCapture(0)    # 视频文件识别    # video_capture = cv2.VideoCapture("video/example.mp4")    font = cv2.FONT_HERSHEY_SIMPLEX    cv2.startWindowThread()    cv2.namedWindow('window_frame')    while True:        _, frame = video_capture.read()        frame = frame[:, ::-1, :]        frame = frame.copy()        # 获得灰度图        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)        # 获取当前帧中的全部人脸        faces = face_detection.detectMultiScale(gray, 1.3, 5)        # 对于所有发现的人脸        for (x, y, w, h) in faces:            # 在脸周围画一个矩形框，(255,0,0)是颜色，2是线宽            cv2.rectangle(frame, (x, y), (x + w, y + h), (84, 255, 159), 2)            # 获取人脸图像            face = gray[y:y + h, x:x + w]            try:                face = cv2.resize(face, (48, 48))            except:                continue            # 扩充维度，shape变为(1,48,48,1)            # 将（1，48，48，1）转换成为(1,1,48,48)            face = np.expand_dims(face, 0)            face = np.expand_dims(face, 0)            # 人脸数据归一化，将像素值从0-255映射到0-1之间            face = preprocess_input(face)            new_face = torch.from_numpy(face)            new_new_face = new_face.float().requires_grad_(False)            # 调用表情识别模型，预测分类            emotion_arg = np.argmax(emotion_classifier.forward(new_new_face).detach().numpy())            emotion = emotion_labels[emotion_arg]            # if one_click:            if flag==3:                text_widget.insert(tk.END, 'emotion by CNN：' + emotion + '\n')                # one_click= False                flag=0            emotion_window.append(emotion)            if len(emotion_window) >= frame_window:                emotion_window.pop(0)            try:                # 获得出现次数最多的分类                emotion_mode = mode(emotion_window)            except:                continue            # 在矩形框上部，输出分类文字            cv2.putText(frame, emotion_mode, (x, y - 30), font, .7, (0, 0, 255), 1, cv2.LINE_AA)        try:            # 将图片从内存中显示到屏幕上            cv2.imshow('window_frame', frame)        except:            continue        # 按q退出        if cv2.waitKey(1) & 0xFF == ord('q'):            break    video_capture.release()    cv2.destroyAllWindows()def begin():    facial_detect_thread = threading.Thread(target=facial_detect, daemon=True)    facial_detect_thread.start()def save_to_file(content, file_name):    desktop_path = os.path.expanduser("~/Desktop")  # 获取桌面路径    file_path = os.path.join(desktop_path, file_name)  # 组合出文件路径    with open(file_path, "w") as file:        file.write(content)    print(f"UIsave to{file_name}")def on_closing():    global  save_counter    file_name = f"ui_content_{save_counter}.txt"    content_to_save = text_widget.get("1.0", tk.END)  # 获取当前文本框的全部内容    save_to_file(content_to_save, file_name)  # 保存内容到文件    save_counter += 1  # 增加保存计数器    root.destroy()  # 关闭窗口# 创建主窗口root = tk.Tk()root.title("TEST WINDOW")# 创建文本框，设置更大的高度和宽度text_widget = tk.Text(root, height=50, width=60)text_widget.pack()# 按钮Button = tk.Button(root,text='OPEN CAMERA',font=("宋体",15),command=begin)Button.pack()# 创建后台线程来运行串口通信和更新UIserial_thread = threading.Thread(target=serial_thread, daemon=True)ui_update_thread = threading.Thread(target=update_ui, daemon=True)serial_thread.start()ui_update_thread.start()# 运行主循环root.protocol("WM_DELETE_WINDOW", on_closing)root.mainloop()