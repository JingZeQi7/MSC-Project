# -*- coding: utf-8 -*-import tkinter as tkimport serialimport threadingimport queueimport winsoundfrom datetime import datetime  # 导入datetime模块import re  # 导入re模块import cv2import torchimport torch.nn as nnimport numpy as npfrom statistics import modeimport warningsimport oswarnings.filterwarnings("ignore")ser = serial.Serial('COM9', 115200)data_queue = queue.Queue()program_start_time = datetime.now()def serial_thread():    try:        while True:            data = ser.readline().decode('utf-8')            data_queue.put(data)    except KeyboardInterrupt:        pass    ser.close()def update_ui():    global one_click    one_click=False    global flag    flag=0    global Test_number    Test_number=1    global save_counter    save_counter = 1    while True:        try:            data = data_queue.get_nowait()            current_time = datetime.now()            time_since_start = current_time - program_start_time            time_since_start_str = str(time_since_start)            # text_widget.insert(tk.END, data)            if flag==0:                text_widget.insert(tk.END, f'Test No.{Test_number}\n')                Test_number+=1            # if '#' in data:            #    text_widget.insert(tk.END, 'chosen emotion Dominance：light\n')            #    # one_click = True            #    flag=flag+1            # if '*' in data:            #    text_widget.insert(tk.END, 'chosen emotion Dominance：Strong\n')            #    # one_click = True            #    flag = flag + 1                # if '4' in data :                #     text_widget.insert(tk.END, 'chosen emotion：angry\n')                #     one_click = 1                # if '5' in data :                #     text_widget.insert(tk.END, 'chosen emotion：angry\n')                #     one_click = 1                # if '6' in data :                #     text_widget.insert(tk.END, 'chosen emotion：angry\n')                #     one_click = 1                # if '7' in data :                #     text_widget.insert(tk.END, 'chosen emotion：angry\n')                #     one_click = 1                # if '8' in data :                #     text_widget.insert(tk.END, 'chosen emotion：angry\n')                #     one_click = 1                # if '9' in data :                #     text_widget.insert(tk.END, 'chosen emotion：angry\n')                #     one_click = 1                # if '0' in data :                #     text_widget.insert(tk.END, 'chosen emotion：angry\n')                #     one_click = 1            text_widget.see(tk.END)            # 播放提示音            winsound.Beep(1000, 300)            # file_name = f"ui_content_{save_counter}.txt"            # content_to_save = text_widget.get("1.0", tk.END)            # save_to_file(content_to_save, file_name)            # save_counter += 1            # 获取当前时间字符串            current_time_str = current_time.strftime('%Y-%m-%d %H:%M:%S')            text_widget.insert(tk.END, '时间：' + current_time_str + '\n')            text_widget.insert(tk.END, 'the time from the beginning：' + time_since_start_str + '\n')            match = re.search(r'val:(\d+)', data)            if match :                extracted_val = match.group(1)                # text_widget.insert(tk.END, '提取到的数字：' + extracted_val + '\n')                if extracted_val == '4':                    text_widget.insert(tk.END, 'chosen emotion Valence：light\n')                    # one_click = True                    flag = flag + 1                elif extracted_val == '5':                    text_widget.insert(tk.END, 'chosen emotion Valence：medium\n')                    # one_click = True                    flag = flag + 1                elif extracted_val == '6':                    text_widget.insert(tk.END, 'chosen emotion Valence：strong\n')                    # one_click = True                    flag = flag + 1                elif extracted_val == '7':                    text_widget.insert(tk.END, 'chosen emotion Arousal：light\n')                    # one_click = True                    flag = flag + 1                elif extracted_val == '8':                    text_widget.insert(tk.END, 'chosen emotion Arousal：medium\n')                    # one_click = True                    flag = flag + 1                elif extracted_val == '9':                    text_widget.insert(tk.END, 'chosen emotion Arousal：strong\n')                    # one_click = True                    flag = flag + 1                elif extracted_val == '0':                    text_widget.insert(tk.END, 'chosen emotion Dominance：medium\n')                    # one_click = True                    flag = flag + 1                text_widget.see(tk.END)            if '#' in data:               text_widget.insert(tk.END, 'chosen emotion Dominance：Strong\n')               # one_click = True               flag=flag+1            if '*' in data:               text_widget.insert(tk.END, 'chosen emotion Dominance：light\n')               # one_click = True               flag = flag + 1        except queue.Empty:            passdef preprocess_input(images):    images = images / 255.0    return imagesdef gaussian_weights_init(m):    classname = m.__class__.__name__    if classname.find('Conv') != -1:        m.weight.data.normal_(0.0, 0.04)class FaceCNN(nn.Module):    def __init__(self):        super(FaceCNN, self).__init__()        self.conv1 = nn.Sequential(                nn.Conv2d(in_channels = 1, out_channels = 64, kernel_size = 3, stride = 1, padding = 1),  # 卷积层                nn.BatchNorm2d(num_features = 64),                nn.RReLU(inplace = True),                nn.MaxPool2d(kernel_size = 2, stride = 2),                )        self.conv2 = nn.Sequential(                nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size = 3, stride = 1, padding = 1),                nn.BatchNorm2d(num_features = 128),                nn.RReLU(inplace = True),                nn.MaxPool2d(kernel_size = 2, stride = 2),                )        self.conv3 = nn.Sequential(                nn.Conv2d(in_channels = 128, out_channels = 256, kernel_size = 3, stride = 1, padding = 1),                nn.BatchNorm2d(num_features = 256),                nn.RReLU(inplace = True),                nn.MaxPool2d(kernel_size = 2, stride = 2),                )        self.conv1.apply(gaussian_weights_init)        self.conv2.apply(gaussian_weights_init)        self.conv3.apply(gaussian_weights_init)        self.fc = nn.Sequential(                nn.Dropout(p = 0.2),                nn.Linear(in_features = 256 * 6 * 6, out_features = 4096),                nn.RReLU(inplace = True),                nn.Dropout(p = 0.5),                nn.Linear(in_features = 4096, out_features = 1024),                nn.RReLU(inplace = True),                nn.Linear(in_features = 1024, out_features = 256),                nn.RReLU(inplace = True),                nn.Linear(in_features = 256, out_features = 7),                )    def forward(self, x):        x = self.conv1(x)        x = self.conv2(x)        x = self.conv3(x)        x = x.view(x.shape[0], -1)        y = self.fc(x)        return ydef facial_detect():    global one_click    global flag    detection_model_path = 'model/haarcascade_frontalface_default.xml'    classification_model_path = 'model/model_cnn.pt'    face_detection = cv2.CascadeClassifier(detection_model_path)    emotion_classifier = torch.load(classification_model_path)    frame_window = 10    emotion_labels = {0: 'angry', 1: 'disgust', 2: 'fear', 3: 'happy', 4: 'sad', 5: 'surprise', 6: 'neutral'}    emotion_window = []    video_capture = cv2.VideoCapture(0)    # video_capture = cv2.VideoCapture("video/example.mp4")    font = cv2.FONT_HERSHEY_SIMPLEX    cv2.startWindowThread()    cv2.namedWindow('window_frame')    while True:        _, frame = video_capture.read()        frame = frame[:, ::-1, :]        frame = frame.copy()        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)        faces = face_detection.detectMultiScale(gray, 1.3, 5)        for (x, y, w, h) in faces:            cv2.rectangle(frame, (x, y), (x + w, y + h), (84, 255, 159), 2)            face = gray[y:y + h, x:x + w]            try:                face = cv2.resize(face, (48, 48))            except:                continue            face = np.expand_dims(face, 0)            face = np.expand_dims(face, 0)            face = preprocess_input(face)            new_face = torch.from_numpy(face)            new_new_face = new_face.float().requires_grad_(False)            emotion_arg = np.argmax(emotion_classifier.forward(new_new_face).detach().numpy())            emotion = emotion_labels[emotion_arg]            # if one_click:            if flag==3:                text_widget.insert(tk.END, 'emotion by CNN：' + emotion + '\n')                # one_click= False                flag=0            emotion_window.append(emotion)            if len(emotion_window) >= frame_window:                emotion_window.pop(0)            try:                emotion_mode = mode(emotion_window)            except:                continue            cv2.putText(frame, emotion_mode, (x, y - 30), font, .7, (0, 0, 255), 1, cv2.LINE_AA)        try:            cv2.imshow('window_frame', frame)        except:            continue        if cv2.waitKey(1) & 0xFF == ord('q'):            break    video_capture.release()    cv2.destroyAllWindows()def begin():    facial_detect_thread = threading.Thread(target=facial_detect, daemon=True)    facial_detect_thread.start()def save_to_file(content, file_name):    desktop_path = os.path.expanduser("~/Desktop")  # 获取桌面路径    file_path = os.path.join(desktop_path, file_name)  # 组合出文件路径    with open(file_path, "w") as file:        file.write(content)    print(f"UIsave to{file_name}")def on_closing():    global  save_counter    file_name = f"ui_content_{save_counter}.txt"    content_to_save = text_widget.get("1.0", tk.END)    save_to_file(content_to_save, file_name)    save_counter += 1    root.destroy()root = tk.Tk()root.title("TEST WINDOW")text_widget = tk.Text(root, height=50, width=60)text_widget.pack()# 按钮Button = tk.Button(root,text='OPEN CAMERA',font=("宋体",15),command=begin)Button.pack()# 创建后台线程来运行串口通信和更新UIserial_thread = threading.Thread(target=serial_thread, daemon=True)ui_update_thread = threading.Thread(target=update_ui, daemon=True)serial_thread.start()ui_update_thread.start()root.protocol("WM_DELETE_WINDOW", on_closing)root.mainloop()